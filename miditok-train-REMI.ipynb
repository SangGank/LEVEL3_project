{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import MMM, MuMIDI, TokenizerConfig, Octuple, REMI\n",
    "from miditok.pytorch_data import DatasetTok, DataCollator\n",
    "from pathlib import Path\n",
    "from symusic import Score\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "import torch\n",
    "\n",
    "from transformers import AutoConfig, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3769"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (0, 127),\n",
    "    \"num_velocities\": 127,\n",
    "    # \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"max_bar_embedding\" : 3000,\n",
    "    \"use_chords\": True,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_programs\": True,\n",
    "    \"num_tempos\": 211,  # number of tempo bins\n",
    "    \"tempo_range\": (40, 250),  # (min, max)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "TOKENIZER_NAME = REMI\n",
    "tokenizer = TOKENIZER_NAME(config)\n",
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_paths = list(Path(\"jazz-midi-366-songs\").glob(\"**/*.mid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_files = len(midi_paths)\n",
    "num_files_valid = round(total_num_files * 0.1) # Validation 비율 자유롭게 변경\n",
    "midi_paths=sorted(midi_paths)\n",
    "midi_paths_valid = midi_paths[:num_files_valid]\n",
    "midi_paths_train = midi_paths[num_files_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: jazz-midi-366-songs: 100%|██████████| 328/328 [00:52<00:00,  6.27it/s]\n",
      "Loading data: jazz-midi-366-songs: 100%|██████████| 36/36 [00:05<00:00,  6.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Creates a Dataset and a collator to be used with a PyTorch DataLoader to train a model\n",
    "# dataset_train = DatasetTok(\n",
    "#     files_paths=midi_paths_train,\n",
    "#     min_seq_len=50,\n",
    "#     max_seq_len=1022,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# dataset_valid = DatasetTok(\n",
    "#     files_paths=midi_paths_valid,\n",
    "#     min_seq_len=50,\n",
    "#     max_seq_len=1022,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# collator = DataCollator(\n",
    "#     tokenizer[\"PAD_None\"], tokenizer[\"BOS_None\"], tokenizer[\"EOS_None\"], copy_inputs_as_labels=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, files_paths, label_path = None, max_length=1022, tokenizer = REMI):  # max_length를 512로 하면 앞, 뒤에 BOS, EOS 토큰이 또 붙어서 길이 514 되고 에러가 나서 일단 510로 함. 디버깅 필요!!\n",
    "\n",
    "        self.tokenized_songs = { 'input_ids' : [], 'attention_mask' : [], 'label' : [] }\n",
    "        self.labels = []\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        for song_path in tqdm(files_paths):\n",
    "            song = self.tokenizer(song_path).ids[:max_length]\n",
    "            song_length = len(song)\n",
    "            attention = [1] * song_length\n",
    "            # \n",
    "            if song_length < max_length:\n",
    "                song += [0] * (max_length - song_length)\n",
    "                attention += [0] * (max_length - song_length)\n",
    "\n",
    "            self.tokenized_songs['input_ids'].append(torch.tensor(song))\n",
    "            self.tokenized_songs['attention_mask'].append(torch.tensor(attention))\n",
    "            \n",
    "            if label_path:\n",
    "\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                self.labels.append(torch.tensor(song))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_songs['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return {\n",
    "            'input_ids': self.tokenized_songs['input_ids'][idx],  \n",
    "            'attention_mask': self.tokenized_songs['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:52<00:00,  6.20it/s]\n",
      "100%|██████████| 36/36 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([   4, 3322, 3559,  ..., 3187, 3259, 3330]),\n",
       "  'attention_mask': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "  'labels': tensor([   4, 3322, 3559,  ..., 3187, 3259, 3330])},\n",
       " {'input_ids': tensor([   4, 3322, 3517,  ..., 3640, 3365, 3208]),\n",
       "  'attention_mask': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "  'labels': tensor([   4, 3322, 3517,  ..., 3640, 3365, 3208])})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = MidiDataset(files_paths = midi_paths_train, tokenizer = tokenizer)\n",
    "dataset_valid = MidiDataset(files_paths = midi_paths_valid, tokenizer = tokenizer)\n",
    "dataset_train[0], dataset_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# first create a custom trainer to log prediction distribution\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def evaluation_loop(\n",
    "        self,\n",
    "        dataloader,\n",
    "        description,\n",
    "        prediction_loss_only=None,\n",
    "        ignore_keys=None,\n",
    "        metric_key_prefix=\"eval\",\n",
    "    ):\n",
    "        # call super class method to get the eval outputs\n",
    "        eval_output = super().evaluation_loop(\n",
    "            dataloader,\n",
    "            description,\n",
    "            prediction_loss_only,\n",
    "            ignore_keys,\n",
    "            metric_key_prefix,\n",
    "        )\n",
    "\n",
    "        return eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer=6\n",
    "n_head=4\n",
    "n_emb=1024\n",
    "context_length = 1024\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_positions=context_length,\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    pad_token_id=tokenizer[\"PAD_None\"],\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    "    n_embd=n_emb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "output_path = \"model\"\n",
    "steps = 400\n",
    "# Commented parameters correspond to the small model\n",
    "config = {\"output_dir\": output_path,\n",
    "          \"num_train_epochs\": 30, # 학습 epoch 자유롭게 변경. 저는 30 epoch 걸어놓고 early stopping 했습니다.\n",
    "          \"per_device_train_batch_size\": 8,\n",
    "          \"per_device_eval_batch_size\": 8,\n",
    "          \"evaluation_strategy\": \"steps\",\n",
    "          \"save_strategy\": \"steps\",\n",
    "          \"eval_steps\": steps,\n",
    "          \"logging_steps\":steps,\n",
    "          \"logging_first_step\": True,\n",
    "          \"save_total_limit\": 5,\n",
    "          \"save_steps\": steps,\n",
    "          \"lr_scheduler_type\": \"cosine\",\n",
    "          \"learning_rate\":5e-4,\n",
    "          \"warmup_ratio\": 0.01,\n",
    "          \"weight_decay\": 0.01,\n",
    "          \"seed\": 1,\n",
    "          \"load_best_model_at_end\": True,\n",
    "          \"metric_for_best_model\": \"eval_loss\", # best model 기준 바꾸고 싶을 경우 이 부분 변경 (default가 eval_loss임)\n",
    "          \"report_to\": \"wandb\"\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mps device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_args = TrainingArguments(**config)\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_valid,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)] # Early Stopping patience 자유롭게 변경\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train the model.\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
