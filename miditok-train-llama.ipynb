{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MIDITok - Tokenizing, Training, Generating!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPmkrdB1s18k"
      },
      "source": [
        "## 1. Install & Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yPGNyAscsvzD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers -q\n",
        "!pip install miditok -q\n",
        "!pip install symusic -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from miditok import MMM, MuMIDI, TokenizerConfig\n",
        "from miditok.pytorch_data import DatasetTok, DataCollator\n",
        "from pathlib import Path\n",
        "from symusic import Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MidiTok 에서 제공하는 tokenizer 클래스로 tokenizer 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a multitrack tokenizer configuration, read the doc to explore other parameters\n",
        "\n",
        "config = TokenizerConfig(\n",
        "    num_velocities=16, \n",
        "    use_chords=True, \n",
        "    use_programs=True,\n",
        "    use_pitch_intervals=True\n",
        "    )\n",
        "\n",
        "TOKENIZER_NAME = MMM # MMM 토크나이저 사용\n",
        "# TOKENIZER_NAME = MuMIDI # MuMIDI 토크나이저 사용\n",
        "tokenizer = TOKENIZER_NAME(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "미디 파일 하나를 시험삼아 토크나이징 해봅니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loads a midi, converts to tokens, and back to a MIDI\n",
        "\n",
        "midi = Score(\"data/jazz-chunked-16bars/003_20thcenturystomp_cleaned/1.mid\")\n",
        "tokens = tokenizer(midi)  # calling the tokenizer will automatically detect MIDIs, paths and tokens\n",
        "converted_back_midi = tokenizer(tokens)  # PyTorch / Tensorflow / Numpy tensors supported"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "토크나이징 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1569"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokens)\n",
        "# tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "토큰에서 다시 생성된 미디 파일 정보 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Score(ttype=Tick, tpq=8, begin=0, end=596, tracks=4, notes=402, time_sig=1, key_sig=0, markers=0, lyrics=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "converted_back_midi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "학습할 미디 파일들의 경로 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1828"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "midi_paths = list(Path(\"data/jazz-chunked-16bars\").glob(\"**/*.mid\"))\n",
        "len(midi_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train / Validation Dataset 구축"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train / valid 데이터셋 split 및 shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split MIDI paths in train/valid/test sets\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "total_num_files = len(midi_paths)\n",
        "num_files_valid = round(total_num_files * 0.1) # Validation 비율 자유롭게 변경\n",
        "shuffle(midi_paths)\n",
        "midi_paths_valid = midi_paths[:num_files_valid]\n",
        "midi_paths_train = midi_paths[num_files_valid:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ⏰ 데이터를 MidiTok Dataset 형태로 처리 (V100 서버 기준 재즈 데이터에 약 1분 소요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading data: data/jazz-chunked-16bars/193_LibertyCity_cleaned: 100%|██████████| 1645/1645 [00:34<00:00, 47.76it/s]\n",
            "Loading data: data/jazz-chunked-16bars/288_shawnuff_cleaned: 100%|██████████| 183/183 [00:03<00:00, 47.71it/s]\n"
          ]
        }
      ],
      "source": [
        "# Creates a Dataset and a collator to be used with a PyTorch DataLoader to train a model\n",
        "dataset_train = DatasetTok(\n",
        "    files_paths=midi_paths_train,\n",
        "    min_seq_len=50,\n",
        "    max_seq_len=2046,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "dataset_valid = DatasetTok(\n",
        "    files_paths=midi_paths_valid,\n",
        "    min_seq_len=50,\n",
        "    max_seq_len=2046,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "collator = DataCollator(\n",
        "    tokenizer[\"PAD_None\"], tokenizer[\"BOS_None\"], tokenizer[\"EOS_None\"], copy_inputs_as_labels=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. HuggingFace와 호환 가능한 형태로 데이터셋 변경\n",
        "❓ HuggingFace Trainer로 train 시키기 위해 아래 과정을 수행합니다.<br>\n",
        "❗️ 아래 셀들이 조금 필요없는 작업일 수 있는데, 일단 구현을 우선으로 작성 해놓았습니다. 혹시 불필요한 과정 발견하시면 제보 부탁드립니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader_train = DataLoader(dataset=dataset_train, collate_fn=collator)\n",
        "data_loader_valid = DataLoader(dataset=dataset_valid, collate_fn=collator)\n",
        "train_tokenized_songs = []\n",
        "valid_tokenized_songs = []\n",
        "for batch in data_loader_train:\n",
        "    train_tokenized_songs.append(batch)\n",
        "for batch in data_loader_valid:\n",
        "    valid_tokenized_songs.append(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(valid_tokenized_songs[0]['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make custom dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MidiDataset(Dataset):\n",
        "    def __init__(self, tokenized_songs, max_length=1022):  # max_length를 512로 하면 앞, 뒤에 BOS, EOS 토큰이 또 붙어서 길이 514 되고 에러가 나서 일단 510로 함. 디버깅 필요!!\n",
        "        self.tokenized_songs = tokenized_songs\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_songs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # item = {key: val.clone().detach() for key, val in self.tokenized_songs[idx].items()}\n",
        "        item = {'input_ids': self.tokenized_songs[idx]['input_ids'][:, :self.max_length].clone().detach().squeeze(),}\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = MidiDataset(train_tokenized_songs)\n",
        "eval_dataset = MidiDataset(valid_tokenized_songs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1022])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]['input_ids'].shape\n",
        "# train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([5, 1024])\n",
            "labels shape: torch.Size([5, 1024])\n",
            "attention_mask shape: torch.Size([5, 1024])\n",
            "out {'input_ids': tensor([[  1,   1,   4,  ..., 269, 106,   2],\n",
            "        [  1,   1, 182,  ...,   0,   0,   0],\n",
            "        [  1,   1,   4,  ..., 109, 116,   2],\n",
            "        [  1,   1, 267,  ...,   0,   0,   0],\n",
            "        [  1,   1,   4,  ..., 116, 304,   2]]), 'labels': tensor([[   1,    1,    4,  ...,  269,  106,    2],\n",
            "        [   1,    1,  182,  ..., -100, -100, -100],\n",
            "        [   1,    1,    4,  ...,  109,  116,    2],\n",
            "        [   1,    1,  267,  ..., -100, -100, -100],\n",
            "        [   1,    1,    4,  ...,  116,  304,    2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n"
          ]
        }
      ],
      "source": [
        "# Test our data_collator\n",
        "out = collator([train_dataset[i] for i in range(5)])\n",
        "\n",
        "for key in out:\n",
        "    print(f\"{key} shape: {out[key].shape}\")\n",
        "\n",
        "print(f\"out {out}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom Trainer 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CYdVIUZ_7xWR"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# first create a custom trainer to log prediction distribution\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def evaluation_loop(\n",
        "        self,\n",
        "        dataloader,\n",
        "        description,\n",
        "        prediction_loss_only=None,\n",
        "        ignore_keys=None,\n",
        "        metric_key_prefix=\"eval\",\n",
        "    ):\n",
        "        # call super class method to get the eval outputs\n",
        "        eval_output = super().evaluation_loop(\n",
        "            dataloader,\n",
        "            description,\n",
        "            prediction_loss_only,\n",
        "            ignore_keys,\n",
        "            metric_key_prefix,\n",
        "        )\n",
        "\n",
        "        return eval_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "세부 training config 정하고, LLaMA-2 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.25s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 4096,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 11008,\n",
              "  \"max_position_embeddings\": 4096,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 32,\n",
              "  \"num_key_value_heads\": 32,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.37.2\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 32000\n",
              "}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaConfig\n",
        "\n",
        "# Remove the extra comma at the end of model_name\n",
        "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
        "model = LlamaForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Display the model configuration\n",
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a copy of the original config\n",
        "new_config = LlamaConfig(\n",
        "    hidden_size = 2048,\n",
        "    intermediate_size = 4096,\n",
        "    num_hidden_layers = 8,\n",
        "    num_attention_heads = 8,\n",
        "    vocab_size = len(tokenizer),\n",
        "    torch_dtype = \"float32\",\n",
        "    pad_token_id = tokenizer['PAD_None'],\n",
        "    bos_token_id = tokenizer['BOS_None'],\n",
        "    eos_token_id = tokenizer['EOS_None']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "downsized_model = LlamaForCausalLM(config=new_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_PROJECT\"] = \"MusicAI\"  # name your W&B project\n",
        "wandb_name = \"llama2-16bars-test\"\n",
        "# wandb_name = \"mistral-7b-16bars-test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training Argument 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ry-BYiGMJiq2"
      },
      "outputs": [],
      "source": [
        "# Create the args for out trainer\n",
        "from argparse import Namespace\n",
        "\n",
        "# Get the output directory with timestamp.\n",
        "output_path = \"models\"\n",
        "steps = 100\n",
        "# Commented parameters correspond to the small model\n",
        "config = {\"output_dir\": output_path,\n",
        "          \"num_train_epochs\": 2, # 학습 epoch 자유롭게 변경. 저는 30 epoch 걸어놓고 early stopping 했습니다.\n",
        "          \"per_device_train_batch_size\": 4,\n",
        "          \"per_device_eval_batch_size\": 2,\n",
        "          \"evaluation_strategy\": \"steps\",\n",
        "          \"save_strategy\": \"steps\",\n",
        "          \"eval_steps\": steps,\n",
        "          \"logging_steps\":steps,\n",
        "          \"logging_first_step\": True,\n",
        "          \"save_total_limit\": 5,\n",
        "          \"save_steps\": steps,\n",
        "          \"lr_scheduler_type\": \"cosine\",\n",
        "          \"learning_rate\":5e-4,\n",
        "          \"warmup_ratio\": 0.01,\n",
        "          \"weight_decay\": 0.01,\n",
        "          # \"seed\": 1, # randomize 해보기\n",
        "          \"load_best_model_at_end\": True,\n",
        "          # \"metric_for_best_model\": \"eval_loss\" # best model 기준 바꾸고 싶을 경우 이 부분 변경 (default가 eval_loss임)\n",
        "          \"report_to\": \"wandb\",\n",
        "          \"run_name\": wandb_name\n",
        "          }\n",
        "\n",
        "args = Namespace(**config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "M07MnTwqJ34f"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "# set_seed(args.seed)\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "D9hBshTJ9coM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# mps device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "downsized_model.to(device)\n",
        "\n",
        "train_args = TrainingArguments(**config)\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=downsized_model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=train_args,\n",
        "    data_collator=collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)] # Early Stopping patience 자유롭게 변경\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 드디어! 학습을 시작하세요! \n",
        "- V100 서버 기준 3 epoch 약 7분 소요\n",
        "- 저는 30 epoch 정도 걸어놓고 Early Stopping 했습니다.\n",
        "- 학습 완료된 후 모델 체크포인트는 models 폴더 안에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SEgCmFiz9v6S"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpatcasso21\u001b[0m (\u001b[33mpatcasso\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.16.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/data/ephemeral/miditok-train-gen/wandb/run-20240219_014449-gcl4mj15</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/patcasso/MusicAI/runs/gcl4mj15' target=\"_blank\">llama2-16bars-test</a></strong> to <a href='https://wandb.ai/patcasso/MusicAI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/patcasso/MusicAI' target=\"_blank\">https://wandb.ai/patcasso/MusicAI</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/patcasso/MusicAI/runs/gcl4mj15' target=\"_blank\">https://wandb.ai/patcasso/MusicAI/runs/gcl4mj15</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1918' max='1918' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1918/1918 38:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.337200</td>\n",
              "      <td>2.500860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.326100</td>\n",
              "      <td>2.235914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.114500</td>\n",
              "      <td>2.054681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.015700</td>\n",
              "      <td>2.000143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.978000</td>\n",
              "      <td>1.977681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.939900</td>\n",
              "      <td>1.921271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.899900</td>\n",
              "      <td>1.871846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.889600</td>\n",
              "      <td>1.856113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.847300</td>\n",
              "      <td>1.828658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.762000</td>\n",
              "      <td>1.805851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.760800</td>\n",
              "      <td>1.777177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.743400</td>\n",
              "      <td>1.743535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.727400</td>\n",
              "      <td>1.718717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.708400</td>\n",
              "      <td>1.694690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.659000</td>\n",
              "      <td>1.677045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.659700</td>\n",
              "      <td>1.660284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.601100</td>\n",
              "      <td>1.648733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.613600</td>\n",
              "      <td>1.641464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.614600</td>\n",
              "      <td>1.639564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1918, training_loss=1.9037819328845107, metrics={'train_runtime': 2305.6827, 'train_samples_per_second': 3.326, 'train_steps_per_second': 0.832, 'total_flos': 1.5768367641427968e+16, 'train_loss': 1.9037819328845107, 'epoch': 2.0})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model.\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. GENERATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "처음 입력할 토큰을 지정해주고, tensor로 바꾸어 generated_ids 변수에 할당합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "initial_token = \"BOS_None\" # 시작 토큰을 BOS로 설정해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_ids = torch.tensor([[tokenizer[initial_token]]])\n",
        "generated_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- iteration number와 현재 시간을 초기화합니다. \n",
        "- ts 변수에 저장된 시간 정보는 지금은 안 쓰이고 있는데, 파일명 등에 사용하시면 나중에 모니터링 하실 때 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Timecode 및 iteration number 초기화\n",
        "import datetime\n",
        "\n",
        "iteration_number = 0\n",
        "ts = datetime.datetime.now().strftime(\"%y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 아래 셀을 실행하여 생성하세요.\n",
        "- 여러 번 실행하면 실행 할 때마다 트랙이 추가됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current iteration : 3\n",
            "tensor([[  1,   1,   4,  ..., 111, 116, 344]])\n"
          ]
        }
      ],
      "source": [
        "# Iteration 몇 번 돌았는지 기록\n",
        "iteration_number += 1\n",
        "print(f\"current iteration : {iteration_number}\")\n",
        "\n",
        "# Encode the conditioning tokens.\n",
        "input_ids = generated_ids.cuda() # 로컬에서 실행할 때는 cuda() 없애주기\n",
        "\n",
        "# Generate more tokens.\n",
        "eos_token_id = tokenizer[\"Track_End\"] # \"Track_End\" 토큰이 나올 때까지 생성 => iteration당 악기 한 트랙씩 생성하는 원리\n",
        "temperature = 0.8 # Temperature를 높이면 생성 결과가 더욱 randomize 되는 것 같습니다.\n",
        "generated_ids = downsized_model.generate(\n",
        "    input_ids,\n",
        "    max_length=1024,\n",
        "    do_sample=True,\n",
        "    temperature=temperature,\n",
        "    eos_token_id=eos_token_id,\n",
        ").cpu()\n",
        "\n",
        "print(generated_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "생성된 토큰 미디 데이터로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Score(ttype=Tick, tpq=8, begin=0, end=1770, tracks=2, notes=228, time_sig=1, key_sig=0, markers=0, lyrics=0)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "midi = tokenizer.tokens_to_midi(generated_ids[0])\n",
        "midi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "변환된 미디 데이터로 test_gen.mid 파일 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "midi.dump_midi(f'./test_gen_iter_{iteration_number}.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🎉 축하합니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 학습 및 생성을 완료하였습니다. 여러 세팅으로 학습해보시고, 생성된 미디 파일을 다운받아 https://bandlab.com/ 등에서 실행시켜보세요\n",
        "- 서버에서 미디 재생이 안 되기 때문에, 생성된 모델과 miditok-gen.ipynb 파일을 다운받아 로컬에서 생성 실험을 계속하시는 것을 추천드립니다!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
